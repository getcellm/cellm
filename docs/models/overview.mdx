---
title: 'Overview'
description: 'Models'
icon: 'ai'
---

Cellms supports both local models running on your own computer and hosted models running in the cloud.

Cellm curates models into three tiers based on their size and capabilities, balancing speed, intelligence, and world knowledge.

|              | Small | Large | Thinking |
| ------------ | -------------- | -------------- | --------------- |
| Speed        | <Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" />  | <Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" />             | <Icon icon="star" iconType="solid" /> | 
| Intelligence  | <Icon icon="star" iconType="solid" /> | <Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" /> | <Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" />  | 
| World Knowledge | <Icon icon="star" iconType="regular" /> | <Icon icon="star" iconType="solid" /> | <Icon icon="star" iconType="solid" /><Icon icon="star" iconType="solid" /> | 

## Select model
A model is denoted by its provider and name seperated by a forward slash (`/`). The default model is Gemma 2 2B served via Ollama. This is denoted by `ollama/gemme2:2b`. Gemma 2 2B is a clever little model thats runs fine on a normal computer without GPU off-loading. Expand the drop-down list in Cellm's ribbon menu select another model: 

<Frame caption="Select a model via the drop-down list.">
	<img src="/images/models/select-model.png" />
</Frame>

The drop-down contains a list of preset models that offers a variety of speed and intelligence trade-offs.

You use another model by typing its name directly in the drop-down textbox, e.g. `ollama/llama3.3`. 